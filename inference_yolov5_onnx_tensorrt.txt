# convert yolov5s.pt to yolov5s.onnx
python export.py --weights yolov5s.pt --include onnx --inplace --device 0 --half

# validation
python val.py --weights yolov5s.onnx --data coco128.yaml --device 0 --half
val: data=/home/nvidia/Downloads/yolov5_v7.0/data/coco128.yaml, weights=['yolov5s.onnx'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.6, max_det=300, task=val, device=0, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs/val, name=exp, exist_ok=False, half=True, dnn=False
YOLOv5 ðŸš€ v7.0-0-g915bbf2 Python-3.8.10 torch-1.12.0a0+2c916ef.nv22.3 CUDA:0 (Xavier, 6846MiB)

Loading yolov5s.onnx for ONNX Runtime inference...
Forcing --batch-size 1 square inference (1,3,640,640) for non-PyTorch models
val: Scanning /home/nvidia/Downloads/datasets/coco128/labels/train2017... 126 images, 2 backgrounds, 0 corrupt: 100
val: New cache created: /home/nvidia/Downloads/datasets/coco128/labels/train2017.cache
                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 
                   all        128        929      0.691      0.633      0.708      0.469
Speed: 1.1ms pre-process, 35.8ms inference, 6.8ms NMS per image at shape (1, 3, 640, 640)
Results saved to runs/val/exp4



# convert yolov5n.pt to yolov5n.onnx
python export.py --weights yolov5n.pt --include onnx --inplace --device 0 --half

# validation
python val.py --weights yolov5n.onnx --data coco128.yaml --device 0 --half
val: data=/home/nvidia/Downloads/yolov5_v7.0/data/coco128.yaml, weights=['yolov5n.onnx'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.6, max_det=300, task=val, device=0, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs/val, name=exp, exist_ok=False, half=True, dnn=False
YOLOv5 ðŸš€ v7.0-0-g915bbf2 Python-3.8.10 torch-1.12.0a0+2c916ef.nv22.3 CUDA:0 (Xavier, 6846MiB)

Loading yolov5n.onnx for ONNX Runtime inference...
Forcing --batch-size 1 square inference (1,3,640,640) for non-PyTorch models
val: Scanning /home/nvidia/Downloads/datasets/coco128/labels/train2017.cache... 126 images, 2 backgrounds, 0 corrup
                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 
                   all        128        929      0.643      0.462      0.545      0.346
Speed: 1.1ms pre-process, 29.7ms inference, 8.1ms NMS per image at shape (1, 3, 640, 640)
Results saved to runs/val/exp5


# tensorrt yolov5s.engine
# convert takes around 25 minutes
python export.py --weights yolov5s.pt --include engine --inplace --device 0 --half

# validation
python val.py --weights yolov5s.engine --data coco128.yaml --device 0
val: data=/home/nvidia/Downloads/yolov5_v7.0/data/coco128.yaml, weights=['yolov5s.engine'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.6, max_det=300, task=val, device=0, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs/val, name=exp, exist_ok=False, half=False, dnn=False
YOLOv5 ðŸš€ v7.0-0-g915bbf2 Python-3.8.10 torch-1.12.0a0+2c916ef.nv22.3 CUDA:0 (Xavier, 6846MiB)

Loading yolov5s.engine for TensorRT inference...
[02/14/2023-23:01:04] [TRT] [I] [MemUsageChange] Init CUDA: CPU +186, GPU +0, now: CPU 286, GPU 5178 (MiB)
[02/14/2023-23:01:04] [TRT] [I] Loaded engine size: 16 MiB
[02/14/2023-23:01:04] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +0, GPU +14, now: CPU 0, GPU 14 (MiB)
[02/14/2023-23:01:04] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +17, now: CPU 0, GPU 31 (MiB)
val: Scanning /home/nvidia/Downloads/datasets/coco128/labels/train2017.cache... 126 images, 2 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 00:00
                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 00:08
                   all        128        929      0.689      0.634      0.708       0.47
Speed: 1.2ms pre-process, 20.4ms inference, 7.9ms NMS per image at shape (1, 3, 640, 640)
Results saved to runs/val/exp7

# half precision
python val.py --weights yolov5s.engine --data coco128.yaml --device 0 --half
val: data=/home/nvidia/Downloads/yolov5_v7.0/data/coco128.yaml, weights=['yolov5s.engine'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.6, max_det=300, task=val, device=0, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs/val, name=exp, exist_ok=False, half=True, dnn=False
YOLOv5 ðŸš€ v7.0-0-g915bbf2 Python-3.8.10 torch-1.12.0a0+2c916ef.nv22.3 CUDA:0 (Xavier, 6846MiB)

Loading yolov5s.engine for TensorRT inference...
[02/14/2023-23:38:07] [TRT] [I] [MemUsageChange] Init CUDA: CPU +186, GPU +0, now: CPU 286, GPU 4970 (MiB)
[02/14/2023-23:38:07] [TRT] [I] Loaded engine size: 16 MiB
[02/14/2023-23:38:07] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +0, GPU +14, now: CPU 0, GPU 14 (MiB)
[02/14/2023-23:38:07] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +17, now: CPU 0, GPU 31 (MiB)
val: Scanning /home/nvidia/Downloads/datasets/coco128/labels/train2017.cache... 126 images, 2 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 00:00
                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 00:08
                   all        128        929      0.689      0.634      0.708       0.47
Speed: 1.2ms pre-process, 20.7ms inference, 7.4ms NMS per image at shape (1, 3, 640, 640)
Results saved to runs/val/exp10




# tensorrt yolov5n.engine
# convert
python export.py --weights yolov5n.pt --include engine --inplace --device 0 --half

# validation
python val.py --weights yolov5n.engine --data coco128.yaml --device 0
val: data=/home/nvidia/Downloads/yolov5_v7.0/data/coco128.yaml, weights=['yolov5n.engine'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.6, max_det=300, task=val, device=0, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs/val, name=exp, exist_ok=False, half=False, dnn=False
YOLOv5 ðŸš€ v7.0-0-g915bbf2 Python-3.8.10 torch-1.12.0a0+2c916ef.nv22.3 CUDA:0 (Xavier, 6846MiB)

Loading yolov5n.engine for TensorRT inference...
[02/14/2023-23:35:48] [TRT] [I] [MemUsageChange] Init CUDA: CPU +186, GPU +0, now: CPU 286, GPU 4946 (MiB)
[02/14/2023-23:35:49] [TRT] [I] Loaded engine size: 6 MiB
[02/14/2023-23:35:49] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +0, GPU +4, now: CPU 0, GPU 4 (MiB)
[02/14/2023-23:35:49] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +10, now: CPU 0, GPU 14 (MiB)
val: Scanning /home/nvidia/Downloads/datasets/coco128/labels/train2017.cache... 126 images, 2 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 00:00
                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 00:08
                   all        128        929      0.642      0.463      0.545      0.348
Speed: 1.4ms pre-process, 19.3ms inference, 11.0ms NMS per image at shape (1, 3, 640, 640)
Results saved to runs/val/exp8

# half precision
python val.py --weights yolov5n.engine --data coco128.yaml --device 0 --half
val: data=/home/nvidia/Downloads/yolov5_v7.0/data/coco128.yaml, weights=['yolov5n.engine'], batch_size=32, imgsz=640, conf_thres=0.001, iou_thres=0.6, max_det=300, task=val, device=0, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs/val, name=exp, exist_ok=False, half=True, dnn=False
YOLOv5 ðŸš€ v7.0-0-g915bbf2 Python-3.8.10 torch-1.12.0a0+2c916ef.nv22.3 CUDA:0 (Xavier, 6846MiB)

Loading yolov5n.engine for TensorRT inference...
[02/14/2023-23:36:58] [TRT] [I] [MemUsageChange] Init CUDA: CPU +186, GPU +0, now: CPU 286, GPU 4953 (MiB)
[02/14/2023-23:36:58] [TRT] [I] Loaded engine size: 6 MiB
[02/14/2023-23:36:58] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +0, GPU +4, now: CPU 0, GPU 4 (MiB)
[02/14/2023-23:36:58] [TRT] [I] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +10, now: CPU 0, GPU 14 (MiB)
val: Scanning /home/nvidia/Downloads/datasets/coco128/labels/train2017.cache... 126 images, 2 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 00:00
                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 00:07
                   all        128        929      0.642      0.463      0.545      0.348
Speed: 1.3ms pre-process, 15.9ms inference, 9.9ms NMS per image at shape (1, 3, 640, 640)
Results saved to runs/val/exp9


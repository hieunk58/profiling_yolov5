# run detect with different options to check inference speed and accuracy
yolov5s

# img-size 640
python detect.py --weights yolov5s.pt --img 640 --source cars.jpg
detect: weights=['yolov5s.pt'], source=cars.jpg, data=data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1
YOLOv5 🚀 v7.0-63-gcdd804d Python-3.8.10 torch-1.12.0a0+2c916ef.nv22.3 CUDA:0 (Xavier, 6846MiB)

Fusing layers... 
YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients
image 1/1 /home/nvidia/Documents/yolov5/cars.jpg: 640x480 2 persons, 25 cars, 1 motorcycle, 1 bus, 2 trucks, 73.7ms
Speed: 2.8ms pre-process, 73.7ms inference, 20.0ms NMS per image at shape (1, 3, 640, 640)

# img-size 640, FP16
python detect.py --weights yolov5s.pt --img 640 --source cars.jpg --half
detect: weights=['yolov5s.pt'], source=cars.jpg, data=data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=True, dnn=False, vid_stride=1
YOLOv5 🚀 v7.0-63-gcdd804d Python-3.8.10 torch-1.12.0a0+2c916ef.nv22.3 CUDA:0 (Xavier, 6846MiB)

Fusing layers... 
YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients
image 1/1 /home/nvidia/Documents/yolov5/cars.jpg: 640x480 2 persons, 25 cars, 1 motorcycle, 1 bus, 2 trucks, 239.1ms
Speed: 1.7ms pre-process, 239.1ms inference, 6.4ms NMS per image at shape (1, 3, 640, 640)
Results saved to runs/detect/exp14


# img-size = 320
python detect.py --weights yolov5s.pt --img 320 --source cars.jpg
detect: weights=['yolov5s.pt'], source=cars.jpg, data=data/coco128.yaml, imgsz=[320, 320], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1
YOLOv5 🚀 v7.0-63-gcdd804d Python-3.8.10 torch-1.12.0a0+2c916ef.nv22.3 CUDA:0 (Xavier, 6846MiB)

Fusing layers... 
YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients
image 1/1 /home/nvidia/Documents/yolov5/cars.jpg: 320x256 1 person, 13 cars, 2 trucks, 71.1ms
Speed: 2.8ms pre-process, 71.1ms inference, 9.0ms NMS per image at shape (1, 3, 320, 320)
Results saved to runs/detect/exp9


# img-size=320, using half precision FP16
python detect.py --weights yolov5s.pt --img 320 --source cars.jpg --half
detect: weights=['yolov5s.pt'], source=cars.jpg, data=data/coco128.yaml, imgsz=[320, 320], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=True, dnn=False, vid_stride=1
YOLOv5 🚀 v7.0-63-gcdd804d Python-3.8.10 torch-1.12.0a0+2c916ef.nv22.3 CUDA:0 (Xavier, 6846MiB)

Fusing layers... 
YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients
image 1/1 /home/nvidia/Documents/yolov5/cars.jpg: 320x256 1 person, 13 cars, 2 trucks, 281.1ms
Speed: 2.1ms pre-process, 281.1ms inference, 8.6ms NMS per image at shape (1, 3, 320, 320)
Results saved to runs/detect/exp10




yolov5n
# normal 640
python detect.py --weights yolov5n.pt --img 640 --source cars.jpg
detect: weights=['yolov5n.pt'], source=cars.jpg, data=data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1
YOLOv5 🚀 v7.0-63-gcdd804d Python-3.8.10 torch-1.12.0a0+2c916ef.nv22.3 CUDA:0 (Xavier, 6846MiB)

Fusing layers... 
YOLOv5n summary: 213 layers, 1867405 parameters, 0 gradients
image 1/1 /home/nvidia/Documents/yolov5/cars.jpg: 640x480 2 persons, 23 cars, 2 buss, 1 truck, 61.8ms
Speed: 2.6ms pre-process, 61.8ms inference, 6.3ms NMS per image at shape (1, 3, 640, 640)
Results saved to runs/detect/exp12

# 640, FP16
python detect.py --weights yolov5n.pt --img 640 --source cars.jpg --half
detect: weights=['yolov5n.pt'], source=cars.jpg, data=data/coco128.yaml, imgsz=[640, 640], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=True, dnn=False, vid_stride=1
YOLOv5 🚀 v7.0-63-gcdd804d Python-3.8.10 torch-1.12.0a0+2c916ef.nv22.3 CUDA:0 (Xavier, 6846MiB)

Fusing layers... 
YOLOv5n summary: 213 layers, 1867405 parameters, 0 gradients
image 1/1 /home/nvidia/Documents/yolov5/cars.jpg: 640x480 2 persons, 23 cars, 2 buss, 1 truck, 211.8ms
Speed: 2.3ms pre-process, 211.8ms inference, 6.8ms NMS per image at shape (1, 3, 640, 640)
Results saved to runs/detect/exp13

# 320
python detect.py --weights yolov5n.pt --img 320 --source cars.jpg
detect: weights=['yolov5n.pt'], source=cars.jpg, data=data/coco128.yaml, imgsz=[320, 320], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=False, dnn=False, vid_stride=1
YOLOv5 🚀 v7.0-63-gcdd804d Python-3.8.10 torch-1.12.0a0+2c916ef.nv22.3 CUDA:0 (Xavier, 6846MiB)

Fusing layers... 
YOLOv5n summary: 213 layers, 1867405 parameters, 0 gradients
image 1/1 /home/nvidia/Documents/yolov5/cars.jpg: 320x256 13 cars, 2 buss, 49.0ms
Speed: 1.6ms pre-process, 49.0ms inference, 5.9ms NMS per image at shape (1, 3, 320, 320)
Results saved to runs/detect/exp15

# 320, FP16
python detect.py --weights yolov5n.pt --img 320 --source cars.jpg --half
detect: weights=['yolov5n.pt'], source=cars.jpg, data=data/coco128.yaml, imgsz=[320, 320], conf_thres=0.25, iou_thres=0.45, max_det=1000, device=, view_img=False, save_txt=False, save_conf=False, save_crop=False, nosave=False, classes=None, agnostic_nms=False, augment=False, visualize=False, update=False, project=runs/detect, name=exp, exist_ok=False, line_thickness=3, hide_labels=False, hide_conf=False, half=True, dnn=False, vid_stride=1
YOLOv5 🚀 v7.0-63-gcdd804d Python-3.8.10 torch-1.12.0a0+2c916ef.nv22.3 CUDA:0 (Xavier, 6846MiB)

Fusing layers... 
YOLOv5n summary: 213 layers, 1867405 parameters, 0 gradients
image 1/1 /home/nvidia/Documents/yolov5/cars.jpg: 320x256 13 cars, 2 buss, 222.1ms
Speed: 1.7ms pre-process, 222.1ms inference, 6.5ms NMS per image at shape (1, 3, 320, 320)
Results saved to runs/detect/exp16

# yolov5m.pt, batch-size 16
python val.py --weights yolov5m.pt --data coco128.yaml --batch-size 16
val: data=/home/nvidia/Downloads/yolov5_v7.0/data/coco128.yaml, weights=['yolov5m.pt'], batch_size=16, imgsz=640, conf_thres=0.001, iou_thres=0.6, max_det=300, task=val, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs/val, name=exp, exist_ok=False, half=False, dnn=False
YOLOv5 🚀 v7.0-0-g915bbf2 Python-3.8.10 torch-1.12.0a0+2c916ef.nv22.3 CUDA:0 (Xavier, 6846MiB)

Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5m.pt to yolov5m.pt...
100%|██████████████████████████████████████| 40.8M/40.8M [00:03<00:00, 11.6MB/s]

Fusing layers... 
YOLOv5m summary: 290 layers, 21172173 parameters, 0 gradients, 48.9 GFLOPs
val: Scanning /home/nvidia/Downloads/datasets/coco128/labels/train2017.cache... 
                 Class     Images  Instances          P          R      mAP50   WARNING ⚠️ NMS time limit 1.300s exceeded
                 Class     Images  Instances          P          R      mAP50   
                   all        128        929      0.736      0.701      0.773      0.552
Speed: 3.4ms pre-process, 110.1ms inference, 20.1ms NMS per image at shape (16, 3, 640, 640)
Results saved to runs/val/exp26

# yolov5l.pt batch-size 16
python val.py --weights yolov5l.pt --data coco128.yaml --batch-size 16
val: data=/home/nvidia/Downloads/yolov5_v7.0/data/coco128.yaml, weights=['yolov5l.pt'], batch_size=16, imgsz=640, conf_thres=0.001, iou_thres=0.6, max_det=300, task=val, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs/val, name=exp, exist_ok=False, half=False, dnn=False
YOLOv5 🚀 v7.0-0-g915bbf2 Python-3.8.10 torch-1.12.0a0+2c916ef.nv22.3 CUDA:0 (Xavier, 6846MiB)

Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5l.pt to yolov5l.pt...
100%|███████████████████████████████████████████████████████████████████████████████████████████████| 89.3M/89.3M [00:08<00:00, 10.6MB/s]

Fusing layers... 
YOLOv5l summary: 367 layers, 46533693 parameters, 0 gradients, 109.0 GFLOPs
val: Scanning /home/nvidia/Downloads/datasets/coco128/labels/train2017.cache... 126 images, 2 backgrounds, 0 corrupt: 100%|██████████| 12
                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 8/8 00:28
                   all        128        929      0.758      0.725      0.813      0.599
Speed: 0.9ms pre-process, 145.1ms inference, 7.3ms NMS per image at shape (16, 3, 640, 640)
Results saved to runs/val/exp27

# yolov5x.pt batch-size 16
python val.py --weights yolov5x.pt --data coco128.yaml --batch-size 16
val: data=/home/nvidia/Downloads/yolov5_v7.0/data/coco128.yaml, weights=['yolov5x.pt'], batch_size=16, imgsz=640, conf_thres=0.001, iou_thres=0.6, max_det=300, task=val, device=, workers=8, single_cls=False, augment=False, verbose=False, save_txt=False, save_hybrid=False, save_conf=False, save_json=False, project=runs/val, name=exp, exist_ok=False, half=False, dnn=False
YOLOv5 🚀 v7.0-0-g915bbf2 Python-3.8.10 torch-1.12.0a0+2c916ef.nv22.3 CUDA:0 (Xavier, 6846MiB)

Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5x.pt to yolov5x.pt...
100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 166M/166M [00:14<00:00, 11.7MB/s]

Fusing layers... 
YOLOv5x summary: 444 layers, 86705005 parameters, 0 gradients, 205.5 GFLOPs
val: Scanning /home/nvidia/Downloads/datasets/coco128/labels/train2017.cache... 126 images, 2 backgrounds, 0 corrupt: 100%|██████████| 12
                 Class     Images  Instances          P          R      mAP50   mAP50-95:  38%|███▊      | 3/8 00:17WARNING ⚠️ NMS time limit 1.300s exceeded
                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100%|██████████| 8/8 00:44
                   all        128        929      0.775      0.664      0.732      0.553
Speed: 0.5ms pre-process, 272.9ms inference, 24.7ms NMS per image at shape (16, 3, 640, 640)
Results saved to runs/val/exp28


# Using yolov5 version 6.0
https://github.com/wang-xinyu/tensorrtx/tree/master/yolov5

# convert .pt to tensorrt
# nano
nvidia@ubuntu:~/Downloads/tensorrtx/yolov5/build$ sudo ./yolov5 -d yolov5n.engine ../images/
inference time: 21ms
inference time: 46ms
inference time: 31ms
inference time: 17ms
inference time: 32ms

# small
nvidia@ubuntu:~/Downloads/tensorrtx/yolov5/build$ sudo ./yolov5 -d yolov5s.engine ../images/
inference time: 24ms
inference time: 35ms
inference time: 35ms
inference time: 39ms
inference time: 24ms


# yolov5n.engine with coco128
inference time: 31ms
inference time: 46ms
inference time: 56ms
inference time: 50ms
inference time: 52ms
inference time: 53ms
inference time: 53ms
inference time: 51ms
inference time: 31ms
inference time: 25ms
inference time: 33ms
inference time: 30ms
inference time: 21ms
inference time: 27ms
inference time: 27ms
inference time: 28ms
inference time: 24ms
inference time: 16ms
inference time: 18ms
inference time: 21ms
inference time: 21ms
inference time: 21ms
inference time: 20ms
inference time: 20ms
inference time: 18ms
inference time: 18ms
inference time: 16ms
inference time: 15ms
inference time: 12ms
inference time: 13ms
inference time: 17ms
inference time: 17ms
inference time: 17ms
inference time: 14ms
inference time: 16ms
inference time: 16ms
inference time: 16ms
inference time: 15ms
inference time: 13ms
inference time: 14ms
inference time: 13ms
inference time: 17ms
inference time: 17ms
inference time: 16ms
inference time: 13ms
inference time: 16ms
inference time: 15ms
inference time: 15ms
inference time: 14ms
inference time: 12ms
inference time: 14ms
inference time: 17ms
inference time: 18ms
inference time: 17ms
inference time: 14ms
inference time: 13ms
inference time: 13ms
inference time: 17ms
inference time: 18ms
inference time: 16ms
inference time: 16ms
inference time: 13ms
inference time: 13ms
inference time: 16ms
inference time: 17ms
inference time: 17ms
inference time: 15ms
inference time: 14ms
inference time: 15ms
inference time: 18ms
inference time: 17ms
inference time: 17ms
inference time: 18ms
inference time: 14ms
inference time: 15ms
inference time: 14ms
inference time: 14ms
inference time: 17ms
inference time: 17ms
inference time: 15ms
inference time: 14ms
inference time: 15ms
inference time: 17ms
inference time: 15ms
inference time: 13ms
inference time: 11ms
inference time: 11ms
inference time: 13ms
inference time: 11ms
inference time: 13ms
inference time: 14ms
inference time: 12ms
inference time: 14ms
inference time: 13ms
inference time: 14ms
inference time: 13ms
inference time: 11ms
inference time: 13ms
inference time: 15ms
inference time: 12ms
inference time: 11ms
inference time: 11ms
inference time: 13ms
inference time: 15ms
inference time: 13ms
inference time: 11ms
inference time: 14ms
inference time: 14ms
inference time: 15ms
inference time: 13ms
inference time: 11ms
inference time: 11ms
inference time: 14ms
inference time: 12ms
inference time: 11ms
inference time: 12ms
inference time: 14ms
inference time: 12ms
inference time: 11ms
inference time: 12ms
inference time: 13ms
inference time: 11ms
inference time: 12ms
inference time: 14ms
inference time: 12ms
inference time: 11ms
inference time: 11ms
inference time: 15ms


# yolov5s.engine with coco128
inference time: 48ms
inference time: 64ms
inference time: 67ms
inference time: 22ms
inference time: 23ms
inference time: 26ms
inference time: 22ms
inference time: 21ms
inference time: 27ms
inference time: 26ms
inference time: 26ms
inference time: 29ms
inference time: 26ms
inference time: 26ms
inference time: 23ms
inference time: 21ms
inference time: 28ms
inference time: 26ms
inference time: 23ms
inference time: 22ms
inference time: 23ms
inference time: 22ms
inference time: 22ms
inference time: 22ms
inference time: 22ms
inference time: 20ms
inference time: 19ms
inference time: 21ms
inference time: 20ms
inference time: 20ms
inference time: 22ms
inference time: 21ms
inference time: 21ms
inference time: 22ms
inference time: 19ms
inference time: 21ms
inference time: 20ms
inference time: 20ms
inference time: 20ms
inference time: 18ms
inference time: 20ms
inference time: 19ms
inference time: 19ms
inference time: 19ms
inference time: 15ms
inference time: 17ms
inference time: 18ms
inference time: 19ms
inference time: 19ms
inference time: 19ms
inference time: 18ms
inference time: 20ms
inference time: 19ms
inference time: 18ms
inference time: 20ms
inference time: 19ms
inference time: 17ms
inference time: 18ms
inference time: 16ms
inference time: 17ms
inference time: 17ms
inference time: 18ms
inference time: 18ms
inference time: 18ms
inference time: 18ms
inference time: 19ms
inference time: 18ms
inference time: 15ms
inference time: 16ms
inference time: 17ms
inference time: 17ms
inference time: 19ms
inference time: 18ms
inference time: 18ms
inference time: 19ms
inference time: 16ms
inference time: 15ms
inference time: 16ms
inference time: 14ms
inference time: 13ms
inference time: 16ms
inference time: 17ms
inference time: 15ms
inference time: 14ms
inference time: 14ms
inference time: 14ms
inference time: 17ms
inference time: 16ms
inference time: 13ms
inference time: 13ms
inference time: 17ms
inference time: 15ms
inference time: 12ms
inference time: 14ms
inference time: 16ms
inference time: 15ms
inference time: 14ms
inference time: 12ms
inference time: 12ms
inference time: 14ms
inference time: 15ms
inference time: 15ms
inference time: 12ms
inference time: 13ms
inference time: 13ms
inference time: 16ms
inference time: 15ms
inference time: 15ms
inference time: 14ms
inference time: 13ms
inference time: 12ms
inference time: 14ms
inference time: 14ms
inference time: 14ms
inference time: 13ms
inference time: 13ms
inference time: 16ms
inference time: 15ms
inference time: 15ms
inference time: 12ms
inference time: 14ms
inference time: 16ms
inference time: 14ms
inference time: 13ms
inference time: 13ms
inference time: 14ms
inference time: 14ms
inference time: 13ms

